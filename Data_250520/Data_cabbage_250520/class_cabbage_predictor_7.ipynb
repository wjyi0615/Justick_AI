{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b7cc9e-56a0-4176-8065-f7902f1a6f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import random\n",
    "import joblib\n",
    "\n",
    "# 고정 시드 설정\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=64, num_layers=2, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, dropout=dropout, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 7)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        return self.fc(out[:, -1, :])\n",
    "\n",
    "class EWC:\n",
    "    def __init__(self, model, dataloader, criterion):\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.dataloader = dataloader\n",
    "        self.params = {n: p.clone().detach() for n, p in model.named_parameters() if p.requires_grad}\n",
    "        self._precision_matrices = self._diag_fisher()\n",
    "\n",
    "    def _diag_fisher(self):\n",
    "        precision = {n: torch.zeros_like(p) for n, p in self.model.named_parameters() if p.requires_grad}\n",
    "        self.model.eval()\n",
    "        for x, y in self.dataloader:\n",
    "            self.model.zero_grad()\n",
    "            out = self.model(x)\n",
    "            loss = self.criterion(out, y)\n",
    "            loss.backward()\n",
    "            for n, p in self.model.named_parameters():\n",
    "                if p.requires_grad:\n",
    "                    precision[n] += p.grad.data.pow(2)\n",
    "        return {n: p / len(self.dataloader) for n, p in precision.items()}\n",
    "\n",
    "    def penalty(self, model):\n",
    "        return sum((self._precision_matrices[n] * (p - self.params[n]).pow(2)).sum()\n",
    "                   for n, p in model.named_parameters() if p.requires_grad)\n",
    "\n",
    "class Predictor7:\n",
    "    def __init__(self, window=7, epochs=30, lr=1e-3, lambda_ewc=100):\n",
    "        self.WINDOW = window\n",
    "        self.EPOCHS = epochs\n",
    "        self.LR = lr\n",
    "        self.LAMBDA_EWC = lambda_ewc\n",
    "        self.feature_cols = ['intake', 'gap', 'price_diff', 'rolling_mean', 'rolling_std']\n",
    "        self.target_col = 'log_price'\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.results = []\n",
    "        self.model = LSTMModel(input_size=len(self.feature_cols))\n",
    "        self.optimizer = AdamW(self.model.parameters(), lr=self.LR)\n",
    "        self.ewc_list = []\n",
    "\n",
    "    def _get_prefix(self, rate):\n",
    "        return \"special\" if rate.lower() == \"special\" else \"high\"\n",
    "\n",
    "    def save(self, rate):\n",
    "        prefix = self._get_prefix(rate)\n",
    "        torch.save(self.model.state_dict(), f\"{prefix}_model_weekly.pth\")\n",
    "        joblib.dump(self.scaler_x, f\"{prefix}_scaler_x.pkl\")\n",
    "        joblib.dump(self.scaler_y, f\"{prefix}_scaler_y.pkl\")\n",
    "\n",
    "    def load(self, rate):\n",
    "        prefix = self._get_prefix(rate)\n",
    "        self.model.load_state_dict(torch.load(f\"{prefix}_model_weekly.pth\"))\n",
    "        self.model.eval()\n",
    "        self.scaler_x = joblib.load(f\"{prefix}_scaler_x.pkl\")\n",
    "        self.scaler_y = joblib.load(f\"{prefix}_scaler_y.pkl\")\n",
    "        self.ewc_list = []\n",
    "\n",
    "    def fit(self, df_raw, cutoff_date=\"2025-05-20\", months=[4, 5, 6], rate=\"Special\"):\n",
    "        self.rate = rate\n",
    "        df = df_raw[df_raw['rate'] == rate].copy()\n",
    "        df['date'] = pd.to_datetime(df[['year', 'month', 'day']])\n",
    "        df = df[df['month'].isin(months)].sort_values('date').reset_index(drop=True)\n",
    "        df['prev_price'] = df['avg_price'].shift(1)\n",
    "        df['price_diff'] = df['avg_price'] - df['prev_price']\n",
    "        df['rolling_mean'] = df['avg_price'].rolling(window=3).mean()\n",
    "        df['rolling_std'] = df['avg_price'].rolling(window=3).std()\n",
    "        df = df.dropna()\n",
    "        df['log_price'] = np.log1p(df['avg_price'])\n",
    "\n",
    "        self.scaler_x = MinMaxScaler()\n",
    "        self.scaler_y = MinMaxScaler()\n",
    "        df[self.feature_cols] = self.scaler_x.fit_transform(df[self.feature_cols])\n",
    "        df[[self.target_col]] = self.scaler_y.fit_transform(df[[self.target_col]])\n",
    "\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.dates = df['date'].values\n",
    "        X_seq, y_seq, date_seq = [], [], []\n",
    "        for i in range(len(df) - self.WINDOW - 6):\n",
    "            window = df.iloc[i:i + self.WINDOW]\n",
    "            targets = df.iloc[i + self.WINDOW:i + self.WINDOW + 7]\n",
    "            X_seq.append(window[self.feature_cols].values)\n",
    "            y_seq.append(targets[self.target_col].values)\n",
    "            date_seq.append(targets['date'].iloc[-1])\n",
    "\n",
    "        self.X_seq = torch.tensor(np.array(X_seq), dtype=torch.float32)\n",
    "        self.y_seq = torch.tensor(np.array(y_seq), dtype=torch.float32)\n",
    "        self.date_seq = date_seq\n",
    "\n",
    "        cutoff = pd.to_datetime(cutoff_date)\n",
    "        init_idx = [i for i, d in enumerate(self.date_seq) if d <= cutoff]\n",
    "        X_init = self.X_seq[init_idx]\n",
    "        y_init = self.y_seq[init_idx]\n",
    "        init_loader = DataLoader(TensorDataset(X_init, y_init), batch_size=16, shuffle=True)\n",
    "\n",
    "        for epoch in range(self.EPOCHS):\n",
    "            self.model.train()\n",
    "            for x, y in init_loader:\n",
    "                self.optimizer.zero_grad()\n",
    "                pred = self.model(x)\n",
    "                loss = self.criterion(pred, y)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "        self.ewc_list = [EWC(self.model, init_loader, self.criterion)]\n",
    "\n",
    "        for i in range(len(self.X_seq)):\n",
    "            if self.date_seq[i] <= cutoff:\n",
    "                continue\n",
    "\n",
    "            self.model.eval()\n",
    "            with torch.no_grad():\n",
    "                pred = self.model(self.X_seq[i].unsqueeze(0)).squeeze(0).numpy()\n",
    "                real = self.y_seq[i].numpy()\n",
    "                pred_log = self.scaler_y.inverse_transform(pred.reshape(-1, 1)).flatten()\n",
    "                real_log = self.scaler_y.inverse_transform(real.reshape(-1, 1)).flatten()\n",
    "                pred_rescaled = np.expm1(pred_log)\n",
    "                real_rescaled = np.expm1(real_log)\n",
    "\n",
    "                for j in range(7):\n",
    "                    pred_date = self.date_seq[i] - pd.Timedelta(days=6 - j)\n",
    "                    self.results.append((pred_date, pred_rescaled[j], real_rescaled[j]))\n",
    "\n",
    "            if i > 0 and self.date_seq[i - 1] > cutoff:\n",
    "                loader = DataLoader(TensorDataset(self.X_seq[i - 1].unsqueeze(0), self.y_seq[i - 1].unsqueeze(0)), batch_size=1)\n",
    "                self.model.train()\n",
    "                for epoch in range(self.EPOCHS):\n",
    "                    for x, y in loader:\n",
    "                        self.optimizer.zero_grad()\n",
    "                        out = self.model(x)\n",
    "                        loss = self.criterion(out, y)\n",
    "                        for ewc in self.ewc_list:\n",
    "                            loss += self.LAMBDA_EWC * ewc.penalty(self.model)\n",
    "                        loss.backward()\n",
    "                        self.optimizer.step()\n",
    "                self.ewc_list.append(EWC(self.model, loader, self.criterion))\n",
    "\n",
    "        last_input = torch.tensor(df.iloc[-self.WINDOW:][self.feature_cols].values, dtype=torch.float32).unsqueeze(0)\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            pred = self.model(last_input).squeeze(0).numpy()\n",
    "            pred_log = self.scaler_y.inverse_transform(pred.reshape(-1, 1)).flatten()\n",
    "            pred_rescaled = np.expm1(pred_log)\n",
    "            start_date = df['date'].iloc[-1] + pd.Timedelta(days=1)\n",
    "            for i in range(7):\n",
    "                self.results.append((start_date + pd.Timedelta(days=i), pred_rescaled[i], None))\n",
    "\n",
    "    def update_one_day(self, df_raw, months=[4, 5, 6]):\n",
    "        if not hasattr(self, 'ewc_list'):\n",
    "            self.ewc_list = []\n",
    "\n",
    "        df = df_raw[df_raw['rate'] == self.rate].copy()\n",
    "        df['date'] = pd.to_datetime(df[['year', 'month', 'day']])\n",
    "        df = df[df['month'].isin(months)].sort_values('date').reset_index(drop=True)\n",
    "        df['prev_price'] = df['avg_price'].shift(1)\n",
    "        df['price_diff'] = df['avg_price'] - df['prev_price']\n",
    "        df['rolling_mean'] = df['avg_price'].rolling(window=3).mean()\n",
    "        df['rolling_std'] = df['avg_price'].rolling(window=3).std()\n",
    "        df = df.dropna()\n",
    "        df['log_price'] = np.log1p(df['avg_price'])\n",
    "\n",
    "        df[self.feature_cols] = self.scaler_x.transform(df[self.feature_cols])\n",
    "        df[[self.target_col]] = self.scaler_y.transform(df[[self.target_col]])\n",
    "\n",
    "        latest_df = df.iloc[-(self.WINDOW + 7):].copy()\n",
    "        x_seq = latest_df.iloc[:self.WINDOW][self.feature_cols].values\n",
    "        y_seq = latest_df.iloc[self.WINDOW:][self.target_col].values\n",
    "\n",
    "        x_tensor = torch.tensor(x_seq, dtype=torch.float32).unsqueeze(0)\n",
    "        y_tensor = torch.tensor(y_seq, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            pred = self.model(x_tensor).squeeze(0).numpy()\n",
    "            pred_log = self.scaler_y.inverse_transform(pred.reshape(-1, 1)).flatten()\n",
    "            pred_rescaled = np.expm1(pred_log)\n",
    "            pred_start_date = df['date'].iloc[-1] + pd.Timedelta(days=1)\n",
    "            for i in range(7):\n",
    "                self.results.append((pred_start_date + pd.Timedelta(days=i), pred_rescaled[i], None))\n",
    "\n",
    "        loader = DataLoader(TensorDataset(x_tensor, y_tensor), batch_size=1)\n",
    "        self.model.train()\n",
    "        for epoch in range(self.EPOCHS):\n",
    "            for x, y in loader:\n",
    "                self.optimizer.zero_grad()\n",
    "                out = self.model(x)\n",
    "                loss = self.criterion(out, y)\n",
    "                for ewc in self.ewc_list:\n",
    "                    loss += self.LAMBDA_EWC * ewc.penalty(self.model)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "        self.ewc_list.append(EWC(self.model, loader, self.criterion))\n",
    "\n",
    "    def predict_next_week(self):\n",
    "        return [round(price, 2) for (_, price, _) in self.results[-7:]]\n",
    "\n",
    "    def predict_next(self):\n",
    "        return round(self.results[-7][1], 2)\n",
    "\n",
    "    def post_latest(self):\n",
    "        return [{\n",
    "            \"year\": date.year,\n",
    "            \"month\": date.month,\n",
    "            \"day\": date.day,\n",
    "            \"price\": round(price, 2),\n",
    "            \"rate\": self.rate\n",
    "        } for (date, price, _) in self.results[-7:]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d21a09b-5479-4be0-87ff-99a30a851083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측된 7일 가격: [5658.52, 5628.3, 5651.59, 5788.09, 5926.67, 6148.4, 6255.99]\n"
     ]
    }
   ],
   "source": [
    "predictor = CabbagePredictor7()\n",
    "df = pd.read_csv(\"cabbage_separated.csv\")\n",
    "predictor.fit(df, cutoff_date=\"2025-05-27\", months=[4, 5, 6], rate=\"HIGH\")\n",
    "predictor.save(\"model_weekly.pth\")\n",
    "\n",
    "# ✅ 출력\n",
    "print(\"예측된 7일 가격:\", predictor.predict_next_week())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb521fc-0f40-4657-acf5-22fb208649ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'year': 2025, 'month': 6, 'day': 1, 'price': 4675.04, 'rate': 'HIGH'},\n",
       " {'year': 2025, 'month': 6, 'day': 2, 'price': 5313.78, 'rate': 'HIGH'},\n",
       " {'year': 2025, 'month': 6, 'day': 3, 'price': 5979.68, 'rate': 'HIGH'},\n",
       " {'year': 2025, 'month': 6, 'day': 4, 'price': 6064.66, 'rate': 'HIGH'},\n",
       " {'year': 2025, 'month': 6, 'day': 5, 'price': 6683.91, 'rate': 'HIGH'},\n",
       " {'year': 2025, 'month': 6, 'day': 6, 'price': 6679.58, 'rate': 'HIGH'},\n",
       " {'year': 2025, 'month': 6, 'day': 7, 'price': 7343.76, 'rate': 'HIGH'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor = CabbagePredictor7()\n",
    "predictor.load(\"model_weekly.pth\")\n",
    "\n",
    "df_new = pd.read_csv(\"cabbage_separated.csv\")\n",
    "predictor.update_one_day(df_new)\n",
    "print(\"내일 가격:\", predictor.predict_next_week()[0])\n",
    "print(\"7일 예측:\", predictor.predict_next_week())\n",
    "print(predictor.post_latest())\n",
    "\n",
    "model = Predictor7()\n",
    "model.fit(df, cutoff_date=\"2025-04-29\", months=[4, 5, 6], rate=\"HIGH\")\n",
    "model.post_latest()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
