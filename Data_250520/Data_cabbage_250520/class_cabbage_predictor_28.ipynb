{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cd2e2a7-4935-47f4-819f-45b92be42075",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import random\n",
    "import joblib\n",
    "\n",
    "# Í≥†Ï†ï ÏãúÎìú\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=64, num_layers=2, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, dropout=dropout, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 28)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        return self.fc(out[:, -1, :])\n",
    "\n",
    "class EWC:\n",
    "    def __init__(self, model, dataloader, criterion):\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.dataloader = dataloader\n",
    "        self.params = {n: p.clone().detach() for n, p in model.named_parameters() if p.requires_grad}\n",
    "        self._precision_matrices = self._diag_fisher()\n",
    "\n",
    "    def _diag_fisher(self):\n",
    "        precision = {n: torch.zeros_like(p) for n, p in self.model.named_parameters() if p.requires_grad}\n",
    "        self.model.eval()\n",
    "        for x, y in self.dataloader:\n",
    "            self.model.zero_grad()\n",
    "            out = self.model(x)\n",
    "            loss = self.criterion(out, y)\n",
    "            loss.backward()\n",
    "            for n, p in self.model.named_parameters():\n",
    "                if p.requires_grad:\n",
    "                    precision[n] += p.grad.data.pow(2)\n",
    "        return {n: p / len(self.dataloader) for n, p in precision.items()}\n",
    "\n",
    "    def penalty(self, model):\n",
    "        return sum((self._precision_matrices[n] * (p - self.params[n]).pow(2)).sum()\n",
    "                   for n, p in model.named_parameters() if p.requires_grad)\n",
    "\n",
    "class CabbagePredictor28:\n",
    "    def __init__(self, window=7, epochs=30, lr=1e-3, lambda_ewc=100):\n",
    "        self.WINDOW = window\n",
    "        self.EPOCHS = epochs\n",
    "        self.LR = lr\n",
    "        self.LAMBDA_EWC = lambda_ewc\n",
    "        self.feature_cols = ['intake', 'gap', 'price_diff', 'rolling_mean', 'rolling_std']\n",
    "        self.target_col = 'log_price'\n",
    "        self.scaler_x = MinMaxScaler()\n",
    "        self.scaler_y = MinMaxScaler()\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.results = []\n",
    "        self.rate = \"Special\"\n",
    "        self.model = LSTMModel(input_size=len(self.feature_cols))\n",
    "        self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=self.LR)\n",
    "        self.ewc_list = []\n",
    "\n",
    "    def save(self, rate):\n",
    "        prefix = \"special\" if rate.lower() == \"special\" else \"high\"\n",
    "        torch.save(self.model.state_dict(), f\"{prefix}_monthly_model.pth\")\n",
    "        joblib.dump(self.scaler_x, f\"{prefix}_monthly_scaler_x.pkl\")\n",
    "        joblib.dump(self.scaler_y, f\"{prefix}_monthly_scaler_y.pkl\")\n",
    "\n",
    "    def load(self, rate):\n",
    "        prefix = \"special\" if rate.lower() == \"special\" else \"high\"\n",
    "        self.model.load_state_dict(torch.load(f\"{prefix}_monthly_model.pth\"))\n",
    "        self.model.eval()\n",
    "        self.scaler_x = joblib.load(f\"{prefix}_monthly_scaler_x.pkl\")\n",
    "        self.scaler_y = joblib.load(f\"{prefix}_monthly_scaler_y.pkl\")\n",
    "        self.ewc_list = []\n",
    "\n",
    "    def predict_next(self):\n",
    "        return self.predict_next_month()[0]\n",
    "\n",
    "    def predict_next_month(self):\n",
    "        return [round(price, 2) for (_, price, _) in self.results[-28:]]\n",
    "\n",
    "    def post_latest(self):\n",
    "        return [{\n",
    "            \"year\": date.year,\n",
    "            \"month\": date.month,\n",
    "            \"day\": date.day,\n",
    "            \"price\": round(price, 2),\n",
    "            \"rate\": self.rate\n",
    "        } for (date, price, _) in self.results[-28:]]\n",
    "\n",
    "    def fit(self, df_raw, cutoff_date=\"2025-05-27\", months=[5, 6], rate=\"Special\"):\n",
    "        self.rate = rate\n",
    "        df = df_raw[df_raw['rate'] == rate].copy()\n",
    "        df['date'] = pd.to_datetime(df[['year', 'month', 'day']])\n",
    "        df = df[df['month'].isin(months)].sort_values('date').reset_index(drop=True)\n",
    "\n",
    "        df['prev_price'] = df['avg_price'].shift(1)\n",
    "        df['price_diff'] = df['avg_price'] - df['prev_price']\n",
    "        df['rolling_mean'] = df['avg_price'].rolling(window=3).mean()\n",
    "        df['rolling_std'] = df['avg_price'].rolling(window=3).std()\n",
    "        df = df.dropna()\n",
    "        df['log_price'] = np.log1p(df['avg_price'])\n",
    "\n",
    "        df[self.feature_cols] = self.scaler_x.fit_transform(df[self.feature_cols])\n",
    "        df[[self.target_col]] = self.scaler_y.fit_transform(df[[self.target_col]])\n",
    "\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.dates = df['date'].values\n",
    "\n",
    "        X_seq, y_seq, date_seq = [], [], []\n",
    "        for i in range(len(df) - self.WINDOW - 27):\n",
    "            window = df.iloc[i:i + self.WINDOW]\n",
    "            targets = df.iloc[i + self.WINDOW:i + self.WINDOW + 28]\n",
    "            X_seq.append(window[self.feature_cols].values)\n",
    "            y_seq.append(targets[self.target_col].values)\n",
    "            date_seq.append(targets['date'].iloc[-1])\n",
    "\n",
    "        self.X_seq = torch.tensor(np.array(X_seq), dtype=torch.float32)\n",
    "        self.y_seq = torch.tensor(np.array(y_seq), dtype=torch.float32)\n",
    "        self.date_seq = date_seq\n",
    "\n",
    "        cutoff = pd.to_datetime(cutoff_date)\n",
    "        init_idx = [i for i, d in enumerate(self.date_seq) if d <= cutoff]\n",
    "        X_init = self.X_seq[init_idx]\n",
    "        y_init = self.y_seq[init_idx]\n",
    "        init_loader = DataLoader(TensorDataset(X_init, y_init), batch_size=16, shuffle=True)\n",
    "\n",
    "        for epoch in range(self.EPOCHS):\n",
    "            self.model.train()\n",
    "            for x, y in init_loader:\n",
    "                self.optimizer.zero_grad()\n",
    "                pred = self.model(x)\n",
    "                loss = self.criterion(pred, y)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "        self.ewc_list = [EWC(self.model, init_loader, self.criterion)]\n",
    "\n",
    "        for i in range(len(self.X_seq)):\n",
    "            if self.date_seq[i] <= cutoff:\n",
    "                continue\n",
    "\n",
    "            self.model.eval()\n",
    "            with torch.no_grad():\n",
    "                pred = self.model(self.X_seq[i].unsqueeze(0)).squeeze(0).numpy()\n",
    "                real = self.y_seq[i].numpy()\n",
    "\n",
    "                pred_log = self.scaler_y.inverse_transform(pred.reshape(-1, 1)).flatten()\n",
    "                real_log = self.scaler_y.inverse_transform(real.reshape(-1, 1)).flatten()\n",
    "\n",
    "                pred_rescaled = np.expm1(pred_log)\n",
    "                real_rescaled = np.expm1(real_log)\n",
    "\n",
    "                for j in range(28):\n",
    "                    pred_date = self.date_seq[i] - pd.Timedelta(days=27 - j)\n",
    "                    self.results.append((pred_date, pred_rescaled[j], real_rescaled[j]))\n",
    "\n",
    "            if i > 0 and self.date_seq[i - 1] > cutoff:\n",
    "                loader = DataLoader(TensorDataset(self.X_seq[i - 1].unsqueeze(0), self.y_seq[i - 1].unsqueeze(0)), batch_size=1)\n",
    "                self.model.train()\n",
    "                for epoch in range(self.EPOCHS):\n",
    "                    for x, y in loader:\n",
    "                        self.optimizer.zero_grad()\n",
    "                        out = self.model(x)\n",
    "                        loss = self.criterion(out, y)\n",
    "                        for ewc in self.ewc_list:\n",
    "                            loss += self.LAMBDA_EWC * ewc.penalty(self.model)\n",
    "                        loss.backward()\n",
    "                        self.optimizer.step()\n",
    "                self.ewc_list.append(EWC(self.model, loader, self.criterion))\n",
    "\n",
    "        last_input = torch.tensor(df.iloc[-self.WINDOW:][self.feature_cols].values, dtype=torch.float32).unsqueeze(0)\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            pred = self.model(last_input).squeeze(0).numpy()\n",
    "            pred_log = self.scaler_y.inverse_transform(pred.reshape(-1, 1)).flatten()\n",
    "            pred_rescaled = np.expm1(pred_log)\n",
    "            start_date = df['date'].iloc[-1] + pd.Timedelta(days=1)\n",
    "            for i in range(28):\n",
    "                self.results.append((start_date + pd.Timedelta(days=i), pred_rescaled[i], None))\n",
    "\n",
    "    def update_one_day(self, df_raw, months=[5, 6]):\n",
    "        if not hasattr(self, 'ewc_list'):\n",
    "            self.ewc_list = []\n",
    "\n",
    "        df = df_raw[df_raw['rate'] == self.rate].copy()\n",
    "        df['date'] = pd.to_datetime(df[['year', 'month', 'day']])\n",
    "        df = df[df['month'].isin(months)].sort_values('date').reset_index(drop=True)\n",
    "\n",
    "        df['prev_price'] = df['avg_price'].shift(1)\n",
    "        df['price_diff'] = df['avg_price'] - df['prev_price']\n",
    "        df['rolling_mean'] = df['avg_price'].rolling(window=3).mean()\n",
    "        df['rolling_std'] = df['avg_price'].rolling(window=3).std()\n",
    "        df = df.dropna()\n",
    "        df['log_price'] = np.log1p(df['avg_price'])\n",
    "\n",
    "        df[self.feature_cols] = self.scaler_x.transform(df[self.feature_cols])\n",
    "        df[[self.target_col]] = self.scaler_y.transform(df[[self.target_col]])\n",
    "\n",
    "        latest_df = df.iloc[-(self.WINDOW + 28):].copy()\n",
    "\n",
    "        x_seq = latest_df.iloc[:self.WINDOW][self.feature_cols].values\n",
    "        y_seq = latest_df.iloc[self.WINDOW:][self.target_col].values\n",
    "\n",
    "        x_tensor = torch.tensor(x_seq, dtype=torch.float32).unsqueeze(0)\n",
    "        y_tensor = torch.tensor(y_seq, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            pred = self.model(x_tensor).squeeze(0).numpy()\n",
    "            pred_log = self.scaler_y.inverse_transform(pred.reshape(-1, 1)).flatten()\n",
    "            pred_rescaled = np.expm1(pred_log)\n",
    "\n",
    "            pred_start_date = df['date'].iloc[-1] + pd.Timedelta(days=1)\n",
    "            for i in range(28):\n",
    "                self.results.append((pred_start_date + pd.Timedelta(days=i), pred_rescaled[i], None))\n",
    "\n",
    "        loader = DataLoader(TensorDataset(x_tensor, y_tensor), batch_size=1)\n",
    "        self.model.train()\n",
    "        for epoch in range(self.EPOCHS):\n",
    "            for x, y in loader:\n",
    "                self.optimizer.zero_grad()\n",
    "                out = self.model(x)\n",
    "                loss = self.criterion(out, y)\n",
    "                for ewc in self.ewc_list:\n",
    "                    loss += self.LAMBDA_EWC * ewc.penalty(self.model)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "        self.ewc_list.append(EWC(self.model, loader, self.criterion))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abf9ecda-2f7a-416c-8301-c6cb7a988d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà ÏòàÏ∏°Îêú Îã§ÏùåÎÇ† Í∞ÄÍ≤©: 5846.0\n",
      "üìÖ ÏòàÏ∏°Îêú Ìñ•ÌõÑ 28Ïùº Í∞ÄÍ≤©: [5846.0, 6035.51, 5918.35, 6021.83, 6078.32, 6325.07, 6320.34, 6206.15, 6254.75, 6662.44, 6493.64, 6464.75, 6655.97, 6739.96, 6827.19, 6681.76, 6445.7, 6453.93, 6731.3, 6627.17, 6400.58, 6521.68, 6691.19, 6497.5, 6536.45, 6330.44, 6438.73, 6711.44]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"cabbage_separated.csv\")\n",
    "\n",
    "#Î∞∞ÏπòÌïôÏäµ\n",
    "predictor = CabbagePredictor28()\n",
    "predictor.fit(df, cutoff_date=\"2025-05-27\", months=[5, 6], rate=\"HIGH\")\n",
    "\n",
    "# Ï†ÄÏû•Ìï†Îïå Îì±Í∏â ÎÇòÎà¥Ïñ¥\n",
    "predictor.save(rate=\"HIGH\")\n",
    "\n",
    "# ÌÖåÏä§Ìä∏Ïö© Ï∂úÎ†•, ÏßÄÏõåÎèÑ Îêå\n",
    "print(\"üìà ÏòàÏ∏°Îêú Îã§ÏùåÎÇ† Í∞ÄÍ≤©:\", predictor.predict_next())\n",
    "print(\"üìÖ ÏòàÏ∏°Îêú Ìñ•ÌõÑ 28Ïùº Í∞ÄÍ≤©:\", predictor.predict_next_month())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd709ae-3092-4d65-bee4-21783d0c70d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
